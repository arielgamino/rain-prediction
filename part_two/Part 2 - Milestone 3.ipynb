{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "-\tTo understand and use K-Fold Cross Validation on the entire dataset\n",
    "-\tTo use GridSearchCV in order to tune the parameters of the logistic regression model in the hopes of finding the best one.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import binarize\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load the dataset that was cleaned (from the data directory) and see if it requires any more cleaning after reading it (hint: Check the first column). Feed the train data into a Logistic Regression model with an arbitrary random state. \n",
    "* Feel free to play around with the parameters of the LogisticRegression class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cleaned data training, test, labels\n",
    "X_train = pd.read_pickle(\"../data/X_train.pkl\")\n",
    "X_test  = pd.read_pickle(\"../data/X_test.pkl\")\n",
    "y_train = pd.read_pickle(\"../data/y_train.pkl\")\n",
    "y_test  = pd.read_pickle(\"../data/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.517958</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.726841</td>\n",
       "      <td>0.646503</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>0.179641</td>\n",
       "      <td>0.434483</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.425178</td>\n",
       "      <td>0.775047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341317</td>\n",
       "      <td>0.848276</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.681710</td>\n",
       "      <td>0.659735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263473</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.593824</td>\n",
       "      <td>0.642722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0  0.524941  0.517958  0.001198     0.143713  0.586207       0.466667   \n",
       "1  0.726841  0.646503  0.011978     0.179641  0.434483       0.360000   \n",
       "2  0.425178  0.775047  0.000000     0.341317  0.848276       0.333333   \n",
       "3  0.681710  0.659735  0.000000     0.263473  0.765517       0.413333   \n",
       "4  0.593824  0.642722  0.000000     0.143713  0.586207       0.440000   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
       "0          0.40      0.651163         0.65         0.55  ...             0.0   \n",
       "1          0.14      0.441860         0.71         0.59  ...             0.0   \n",
       "2          0.30      0.255814         0.06         0.02  ...             0.0   \n",
       "3          0.44      0.441860         0.59         0.53  ...             0.0   \n",
       "4          0.00      0.162791         0.72         0.53  ...             0.0   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
       "0            0.0           1.0            0.0             0.0             0.0   \n",
       "1            0.0           0.0            1.0             0.0             0.0   \n",
       "2            0.0           0.0            0.0             0.0             0.0   \n",
       "3            0.0           0.0            0.0             0.0             0.0   \n",
       "4            0.0           0.0            1.0             0.0             0.0   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0            0.0           0.0             0.0             0.0  \n",
       "1            0.0           0.0             0.0             0.0  \n",
       "2            0.0           0.0             0.0             0.0  \n",
       "3            0.0           0.0             0.0             0.0  \n",
       "4            0.0           0.0             0.0             0.0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression - Rain Prediction\n",
    "log_regression = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "log_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Use cross_validate from sklearn.model_selection to understand how cross validation works. \n",
    "* Instead of setting cv as an integer value, try using KFold (with >2 folds) from sklearn.model_selection as an alternative.\n",
    "* You can use either the training set or concatenate the training set to the test set when using cross_validate in order to obtain the metrics (obtain accuracy and AUC score).\n",
    "* Take the mean of all the values to obtain a single accuracy and single AUC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all values\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold cross validation k=10\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-fold of 5\n",
    "cv_results = cross_validate(log_regression, X, y, cv=cv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8472639692200834"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain accuracy by averaging all scores\n",
    "accuracy = mean(cv_results['test_score'])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation to obtain multiple predictions. Keep track of accuracy and AUC\n",
    "accuracy_all = []\n",
    "auc_all = []\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):    \n",
    "    log_regression.fit(X.iloc[train], y.iloc[train])\n",
    "    y_prediction_test = log_regression.predict(X.iloc[test])\n",
    "    test_accuracy_score = accuracy_score(y.iloc[test], y_prediction_test)\n",
    "    accuracy_all.append(test_accuracy_score)\n",
    "    AUC_score = roc_auc_score(y.iloc[test], y_prediction_test)\n",
    "    auc_all.append(AUC_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8453586497890295,\n",
       " 0.8476793248945148,\n",
       " 0.8431786216596343,\n",
       " 0.8453477741050707,\n",
       " 0.8524509459174344,\n",
       " 0.8499894507349322,\n",
       " 0.85069273507279,\n",
       " 0.8461213868767142,\n",
       " 0.8461917153105001,\n",
       " 0.8456290878402138]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7211433512312738,\n",
       " 0.7287229303570166,\n",
       " 0.7201244174231188,\n",
       " 0.7223996308666248,\n",
       " 0.729182454365737,\n",
       " 0.7323710429612815,\n",
       " 0.7334408885328306,\n",
       " 0.7270266863538999,\n",
       " 0.72912810556455,\n",
       " 0.7217109916456106]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracy = mean(accuracy_all)\n",
    "final_auc = mean(auc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (average):0.8473\n",
      "AUC (average):0.7265\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy (average):{final_accuracy:.4f}\")\n",
    "print(f\"AUC (average):{final_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original accuracy from the logistic regression model was 0.8496, not much different from the one obtained using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Use GridSearchCV on a logistic regression model to find the best parameters.\n",
    "* As a minimum, find a suitable value of C along with the best solver. You are free to include other parameters in your parameter grid. Keep in mind the more parameters there are, the more models are iterated, leading to a longer time needed to compute.\n",
    "* Do not forget to use the cv argument.\n",
    "* Once GridSearchCV is instantiated, fit the classifier on the training data. This may take some time.\n",
    "* Have a look at the best estimator and the parameters for the same once the data has been fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used for gird search\n",
    "gs_parameters = [{'penalty':['l1','l2'], 'C':[0.001, .009, 0.01, 0.9, 1, 10, 100, 1000], 'solver':['liblinear','lbfgs','saga']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate gridsearch, use all available processors to speed up\n",
    "grid_search = GridSearchCV(estimator = LogisticRegression(),  \n",
    "                           param_grid = gs_parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  6.3min finished\n",
      "/root/anaconda3/envs/manning/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.001, 0.009, 0.01, 0.9, 1, 10, 100, 1000],\n",
       "                          'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear', 'lbfgs', 'saga']}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the best params\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Use this new logistic regression classifier to predict the labels for X_test and compute the accuracy, confusion matrix and classification report.\n",
    "* Compare these values to the initial model we created.\n",
    "* Change the threshold value to a suitable value to decrease the type 2 error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_gs_test = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.8473926650022856\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy\n",
    "print(f\"Accuracy Score:{accuracy_score(y_test,y_predicted_gs_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.770356572645024, 0.454331450094162, 0.5715695952615992, None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print precision, recall, f-score\n",
    "precision_recall_fscore_support(y_test,y_predicted_gs_test, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21204,   863],\n",
       "       [ 3477,  2895]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain tp, fp, fn, tp\n",
    "confusion_matrix(y_test,y_predicted_gs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     22067\n",
      "           1       0.77      0.45      0.57      6372\n",
      "\n",
      "    accuracy                           0.85     28439\n",
      "   macro avg       0.81      0.71      0.74     28439\n",
      "weighted avg       0.84      0.85      0.83     28439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicted_gs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are comparable to original model:\n",
    "\n",
    "- Original accuracy: 0.8496\n",
    "- Original precision: 0.7681\n",
    "- Original recall: 0.4606\n",
    "- Original f score: 0.5759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold:0.1\n",
      "False Positives (Type I errors):7,619\n",
      "False Negatives (Type II errors):745\n",
      "Accuracy:70.59%\n",
      "Precision:42.48%\n",
      "Recall:88.31%\n",
      "\n",
      "Threshold:0.2\n",
      "False Positives (Type I errors):3,854\n",
      "False Negatives (Type II errors):1,563\n",
      "Accuracy:80.95%\n",
      "Precision:55.51%\n",
      "Recall:75.47%\n",
      "\n",
      "Threshold:0.3\n",
      "False Positives (Type I errors):2,245\n",
      "False Negatives (Type II errors):2,299\n",
      "Accuracy:84.02%\n",
      "Precision:64.47%\n",
      "Recall:63.92%\n",
      "\n",
      "Threshold:0.4\n",
      "False Positives (Type I errors):1,380\n",
      "False Negatives (Type II errors):2,888\n",
      "Accuracy:84.99%\n",
      "Precision:71.63%\n",
      "Recall:54.68%\n",
      "\n",
      "Threshold:0.5\n",
      "False Positives (Type I errors):863\n",
      "False Negatives (Type II errors):3,477\n",
      "Accuracy:84.74%\n",
      "Precision:77.04%\n",
      "Recall:45.43%\n",
      "\n",
      "Threshold:0.6\n",
      "False Positives (Type I errors):497\n",
      "False Negatives (Type II errors):4,044\n",
      "Accuracy:84.03%\n",
      "Precision:82.41%\n",
      "Recall:36.53%\n",
      "\n",
      "Threshold:0.7\n",
      "False Positives (Type I errors):244\n",
      "False Negatives (Type II errors):4,618\n",
      "Accuracy:82.90%\n",
      "Precision:87.79%\n",
      "Recall:27.53%\n",
      "\n",
      "Threshold:0.8\n",
      "False Positives (Type I errors):105\n",
      "False Negatives (Type II errors):5,204\n",
      "Accuracy:81.33%\n",
      "Precision:91.75%\n",
      "Recall:18.33%\n",
      "\n",
      "Threshold:0.9\n",
      "False Positives (Type I errors):28\n",
      "False Negatives (Type II errors):5,808\n",
      "Accuracy:79.48%\n",
      "Precision:95.27%\n",
      "Recall:8.85%\n"
     ]
    }
   ],
   "source": [
    "# Generate thresholds 0.1 to 0.9 and calculate confusion matrix\n",
    "for i in range(1,10):\n",
    "    # Predict original probability of rain (column 1)\n",
    "    y_rain_prediction = grid_search.predict_proba(X_test)[:,1]    \n",
    "    # Reshape to pass to binarize function\n",
    "    y_rain_prediction = y_rain_prediction.reshape(-1,1)\n",
    "    new_threshold = i/10\n",
    "    print(f\"\\nThreshold:{new_threshold}\")\n",
    "    y_new_rain_prediction = binarize(y_rain_prediction,threshold=new_threshold)\n",
    "    new_confusion_m = confusion_matrix(y_test,y_new_rain_prediction)    \n",
    "    # Obtain tp, fp, fn, tp\n",
    "    TN, FP, FN, TP = new_confusion_m.ravel()\n",
    "    print(f\"False Positives (Type I errors):{FP:,}\")\n",
    "    print(f\"False Negatives (Type II errors):{FN:,}\")\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    print(f\"Accuracy:{accuracy*100:.2f}%\")\n",
    "    print(f\"Precision:{precision*100:.2f}%\")\n",
    "    print(f\"Recall:{recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a threshold of 0.3 the Type II errors start to increase drastically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Compare it to the initial model we created and state your inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original model had an accuracy of Original accuracy: 0.8496, at a threshold of 0.3 or 0.4 the accuracy is similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.  Save the model as a pickle file using the joblib library. The model is now ready for deployment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid_search,'../data/logistic_regression_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manning",
   "language": "python",
   "name": "manning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
